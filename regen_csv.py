#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSV Regeneration Service - Main orchestrator for the 6-PASS system

–ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ CSV —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º 6-PASS —Å–∏—Å—Ç–µ–º—ã:
- PASS 1: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–∞ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É (–ø–∞–ø–∫–∞ ‚Üí —Ñ–∞–π–ª ‚Üí –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ)
- PASS 2: [–ø—Ä–æ–ø—É—â–µ–Ω]
- PASS 3: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –∞–≤—Ç–æ—Ä–æ–≤
- PASS 4: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞
- PASS 5: –ü–µ—Ä–µ–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ conversions
- PASS 6: –†–∞—Å–∫—Ä—ã—Ç–∏–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥—É–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É:
- fb2_author_extractor.py - PASS 1 –ª–æ–≥–∏–∫–∞
- author_normalizer_extended.py - PASS 3, 5, 6 –ª–æ–≥–∏–∫–∞
- author_processor.py - PASS 4 –ª–æ–≥–∏–∫–∞ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞
"""

import csv
import json
import os
import re
import unicodedata
from pathlib import Path
from typing import List, Dict, Optional, Callable, Tuple
from dataclasses import asdict
import sys

try:
    from author_normalizer_extended import (
        BookRecord,
        apply_author_normalization,
        apply_surname_conversions_to_records,
        apply_author_consensus,
        build_authors_map,
        expand_abbreviated_authors,
    )
    from fb2_author_extractor import FB2AuthorExtractor
    from settings_manager import SettingsManager
    from logger import Logger
except ImportError:
    from .author_normalizer_extended import (
        BookRecord,
        apply_author_normalization,
        apply_surname_conversions_to_records,
        apply_author_consensus,
        build_authors_map,
        expand_abbreviated_authors,
    )
    from .fb2_author_extractor import FB2AuthorExtractor
    from .settings_manager import SettingsManager
    from .logger import Logger


class RegenCSVService:
    """Service –¥–ª—è —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ CSV —Ñ–∞–π–ª–∞ —Å –∞–≤—Ç–æ—Ä–∞–º–∏."""
    
    def __init__(self, config_path: str = 'config.json'):
        """Initialize the service.
        
        Args:
            config_path: Path to config.json
        """
        self.config_path = Path(config_path)
        self.settings = SettingsManager(config_path)
        self.logger = Logger()
        self.extractor = FB2AuthorExtractor(config_path)
        
        # FB2 —Ñ–∞–π–ª—ã —Å–∫–∞–Ω–∏—Ä—É—é—Ç—Å—è –∏–∑ last_scan_path (—Ä–∞–±–æ—á–µ–π –ø–∞–ø–∫–∏), –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–π –≤ config.json
        self.work_dir = Path(self.settings.get_last_scan_path())
        self.folder_parse_limit = self.settings.get_folder_parse_limit()
        
        self.records: List[BookRecord] = []
        
        # –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞/–ø–∞–ø–∫–∏
        self.author_patterns = self._load_author_patterns()
        
        # –ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∏–º—ë–Ω –∞–≤—Ç–æ—Ä–æ–≤ (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è –∏–º–µ–Ω–∏)
        self.author_names = self._load_author_names()
        
        # –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏–º—ë–Ω
        self.author_name_patterns = self._load_author_name_patterns()
    
    def _load_author_patterns(self) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞.
        
        Returns:
            List of pattern dicts with 'pattern' key
        """
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            patterns = config_data.get('author_series_patterns_in_files', [])
            return patterns if patterns else []
        except Exception as e:
            self.logger.log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∞–≤—Ç–æ—Ä–æ–≤: {e}")
            return []
    
    def _load_author_names(self) -> set:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∏–º—ë–Ω –∞–≤—Ç–æ—Ä–æ–≤ (–º—É–∂. + –∂–µ–Ω.).
        
        Returns:
            Set –∏–º—ë–Ω –≤ –Ω–∏–∂–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ
        """
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            
            male_names = set(name.lower() for name in config_data.get('male_names', []))
            female_names = set(name.lower() for name in config_data.get('female_names', []))
            return male_names | female_names
        except Exception as e:
            self.logger.log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø–∏—Å–∫–∞ –∏–º—ë–Ω: {e}")
            return set()
    
    def _load_author_name_patterns(self) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∏–º—ë–Ω –∞–≤—Ç–æ—Ä–æ–≤.
        
        Returns:
            List of name pattern dicts
        """
        try:
            with open(self.config_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            patterns = config_data.get('author_name_patterns', [])
            return patterns if patterns else []
        except Exception as e:
            self.logger.log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏–º—ë–Ω: {e}")
            return []
    
    def _normalize_diacritics(self, text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –¥–∏–∞–∫—Ä–∏—Ç–∏–∫—É (—É–¥–∞–ª–∏—Ç—å —ë‚Üí–µ, –∏ —Ç.–¥.).
        
        –ü—Ä–∏–º–µ—Ä: "–ñ–µ—Ä–µ–±—å—ë–≤" ‚Üí "–ñ–µ—Ä–µ–±—å–µ–≤"
        –ò—Å–ø–æ–ª—å–∑—É–µ–º NFD decomposition –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ–º combining marks.
        
        Args:
            text: –¢–µ–∫—Å—Ç —Å –≤–æ–∑–º–æ–∂–Ω–æ–π –¥–∏–∞–∫—Ä–∏—Ç–∏–∫–æ–π
            
        Returns:
            –¢–µ–∫—Å—Ç –±–µ–∑ –¥–∏–∞–∫—Ä–∏—Ç–∏–∫–∏
        """
        if not text:
            return text
        # NFD —Ä–∞–∑–±–∏–≤–∞–µ—Ç –±—É–∫–≤—ã —Å –¥–∏–∞–∫—Ä–∏—Ç–∏–∫–æ–π –Ω–∞ –±–∞–∑–æ–≤—É—é –±—É–∫–≤—É –∏ –∫–æ–º–±–∏–Ω–∏—Ä—É—é—â–∏–µ —Å–∏–º–≤–æ–ª—ã
        nfd = unicodedata.normalize('NFD', text)
        # –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ–º –¥–∏–∞–∫—Ä–∏—Ç–∏–∫—É (–∫–∞—Ç–µ–≥–æ—Ä–∏—è Mn = combining mark nonspacing)
        return ''.join(c for c in nfd if unicodedata.category(c) != 'Mn')
    
    def _looks_like_author_name(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—ã–≥–ª—è–¥–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –∫–∞–∫ –∏–º—è –∞–≤—Ç–æ—Ä–∞ (–ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Ç–æ–ª—å–∫–æ).
        
        –ù–∞ –æ—Ç–ª–∏—á–∏–µ –æ—Ç _contains_author_name, —ç—Ç–æ –ù–ï –ø—Ä–æ–≤–µ—Ä—è–µ—Ç:
        - –ù–∞–ª–∏—á–∏–µ –≤ known_authors
        - –°–ª–æ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É:
        - –ù–µ –ø—É—Å—Ç–æ –∏ –Ω–µ –±—Ä–∞–∫
        - –°–æ–¥–µ—Ä–∂–∏—Ç –±—É–∫–≤—ã (–∫–∏—Ä–∏–ª–ª–∏—Ü—É –∏–ª–∏ –ª–∞—Ç–∏–Ω–∏—Ü—É)
        - –ù–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π —á–∏—Å–µ–ª (999 999)
        - –ù–µ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–µ
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            
        Returns:
            True –µ—Å–ª–∏ –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –∏–º—è, False –∏–Ω–∞—á–µ
        """
        if not text or len(text) < 2:
            return False
        
        # –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ - –≤–µ—Ä–æ—è—Ç–Ω–æ –Ω–µ –∏–º—è
        if len(text) > 100:
            return False
        
        # –°–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –±—É–∫–≤—É (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞ –∏–ª–∏ –ª–∞—Ç–∏–Ω–∏—Ü–∞)?
        has_letter = any(c.isalpha() for c in text)
        if not has_letter:
            return False
        
        # –°–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏?
        if re.search(r'\d{3,}', text):  # 999 –∏ –±–æ–ª–µ–µ –ø–æ–¥—Ä—è–¥
            return False
        
        # –°–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã?
        dangerous_chars = ['@', '#', '$', '%', '^', '&', '*', '|', '\\', '/']
        if any(c in text for c in dangerous_chars):
            return False
        
        return True
    
    def _contains_author_name(self, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –∏–º—è –∞–≤—Ç–æ—Ä–∞ (–ø–æ –¥–≤—É–º —É—Ä–æ–≤–Ω—è–º).
        
        –£—Ä–æ–≤–µ–Ω—å 1: –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –µ—Å—Ç—å –ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–æ–µ –∏–º—è –≤ —Ç–µ–∫—Å—Ç–µ
        –£—Ä–æ–≤–µ–Ω—å 2: –ü–æ–ª–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ —Ç–µ–∫—Å—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º –∏–º—ë–Ω
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (–ø–∞–ø–∫–∞ –∏–ª–∏ –∏–º—è —Ñ–∞–π–ª–∞)
            
        Returns:
            True –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –∏–º—è, False –∏–Ω–∞—á–µ
        """
        # –£—Ä–æ–≤–µ–Ω—å 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–º –∏–º–µ–Ω–∞–º
        text_lower = text.lower()
        # –í–ê–ñ–ù–û: –ù–æ—Ä–º–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∏–∞–∫—Ä–∏—Ç–∏–∫—É! –ñ–µ—Ä–µ–±—å—ë–≤ ‚Üí –∂–µ—Ä–µ–±—å–µ–≤
        text_normalized = self._normalize_diacritics(text_lower)
        
        words = re.split(r'[,\-\.\s¬´¬ª()]+', text_normalized)
        
        for word in words:
            word_clean = word.strip()
            if word_clean and word_clean in self.author_names:
                return True
        
        # –£—Ä–æ–≤–µ–Ω—å 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
        for pattern_dict in self.author_name_patterns:
            pattern_desc = pattern_dict.get('pattern', '')
            regex = self._pattern_to_regex(pattern_desc)
            if regex and re.search(regex, text, re.IGNORECASE):
                return True
        
        return False
    
    def _pattern_to_regex(self, pattern_desc: str) -> Optional[str]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –∏–º–µ–Ω–∏ –≤ —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ.
        
        Args:
            pattern_desc: Description like "(Surname)" or "(Surname) (Name)"
            
        Returns:
            Regex pattern or None
        """
        # –ú–∞–ø–ø–∏–Ω–≥ –æ–ø–∏—Å–∞–Ω–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–∞ regex
        patterns_map = {
            "(Name)": r'\b[A-Z–ê-–Ø][a-z–∞-—è]{1,}\b',  # –û–¥–Ω–æ —Å–ª–æ–≤–æ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã
            "(Surname)": r'\b[A-Z–ê-–Ø][a-z–∞-—è]{1,}\b',
            "(Surname) (Name)": r'\b[A-Z–ê-–Ø][a-z–∞-—è]{1,}\s+[A-Z–ê-–Ø][a-z–∞-—è]{1,}\b',
            "(Name) (Surname)": r'\b[A-Z–ê-–Ø][a-z–∞-—è]{1,}\s+[A-Z–ê-–Ø][a-z–∞-—è]{1,}\b',
            "(Surname) (Name) (Patronymic)": r'\b[A-Z–ê-–Ø][a-z–∞-—è]{1,}\s+[A-Z–ê-–Ø][a-z–∞-—è]{1,}\s+[A-Z–ê-–Ø][a-z–∞-—è]{1,}\b',
            "(Surname) ((Name))": r'\b[A-Z–ê-–Ø][a-z–∞-—è]{1,}\s*\([A-Z–ê-–Ø][a-z–∞-—è]{1,}\)\b',
            "(Surname) (Initial). (Name)": r'\b[A-Z–ê-–Ø][a-z–∞-—è]{1,}\s+[A-Z–ê-–Ø]\.?\s+[A-Z–ê-–Ø][a-z–∞-—è]{1,}\b',
            "(N). (Surname)": r'\b[A-Z–ê-–Ø]\.?\s+[A-Z–ê-–Ø][a-z–∞-—è]{1,}\b',
        }
        
        return patterns_map.get(pattern_desc)
    
    def _file_pattern_to_regex(self, pattern_desc: str) -> Optional[Tuple[str, List[str]]]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ —Ñ–∞–π–ª–∞ –≤ regex —Å –≥—Ä—É–ø–ø–∞–º–∏.
        
        Args:
            pattern_desc: Description like "Author - Title" or "Author - Title (Series. service_words)"
            
        Returns:
            Tuple (regex_pattern, group_names) –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω
        """
        # –ú–∞–ø–ø–∏–Ω–≥ –æ–ø–∏—Å–∞–Ω–∏–π –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ —Ñ–∞–π–ª–æ–≤ –Ω–∞ regex —Å –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–º–∏ –≥—Ä—É–ø–ø–∞–º–∏
        patterns_map = {
            "(Author) - Title": (
                r'^\((?P<author>[^)]+)\)\s*-\s*(?P<title>.+)$',
                ['author', 'title']
            ),
            "Author - Title": (
                r'^(?P<author>.*?)\s*-\s*(?P<title>[^(]+)(?:\(.*\))?$',
                ['author', 'title']
            ),
            "Author. Title": (
                r'^(?P<author>[^.]+)\.\s*(?P<title>.+?)(?:\(.+\))?$',
                ['author', 'title']
            ),
            "Title (Author)": (
                r'^(?P<title>.*?)\s*\((?P<author>[^)]+)\)$',
                ['title', 'author']
            ),
            "Title - (Author)": (
                r'^(?P<title>.*?)\s*-\s*\((?P<author>[^)]+)\)$',
                ['title', 'author']
            ),
            "Author - Series.Title": (
                r'^(?P<author>.*?)\s*-\s*(?P<series>[^.]+)\.\s*(?P<title>.+)$',
                ['author', 'series', 'title']
            ),
            "Author. Series. Title": (
                r'^(?P<author>[^.]+)\.\s*(?P<series>[^.]+)\.\s*(?P<title>.+)$',
                ['author', 'series', 'title']
            ),
            "Author. Title. (Series)": (
                r'^(?P<author>[^.]+)\.\s*(?P<title>[^.]+)\.\s*\((?P<series>[^)]+)\)$',
                ['author', 'title', 'series']
            ),
            "Author - Title (Series. service_words)": (
                r'^(?P<author>[^-]+?)\s*-\s*(?P<title>[^(]+?)\s*\((?P<series>[^)]+)\)(?:\s*-\s*.+)?$',
                ['author', 'title', 'series']
            ),
            "Author. Title (Series. service_words)": (
                r'^(?P<author>[^.]+)\.\s*(?P<title>[^(]+?)\s*\((?P<series>[^)]+)\)$',
                ['author', 'title', 'series']
            ),
            "Author, Author - Title (Series. service_words)": (
                r'^(?P<author>[^-]+?\s*,\s*[^-]+?)\s*-\s*(?P<title>[^(]+?)\s*\((?P<series>[^)]+)\)(?:\s*-\s*.+)?$',
                ['author', 'title', 'series']
            ),
        }
        
        return patterns_map.get(pattern_desc)
    
    def _extract_author_from_filename_by_patterns(self, filename: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á—å –∞–≤—Ç–æ—Ä–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞, –ø–æ–¥–±–∏—Ä–∞—è –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ.
        
        –õ–æ–≥–∏–∫–∞:
        1. –ü–µ—Ä–µ–±—Ä–∞—Ç—å –í–°–ï –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ author_series_patterns_in_files
        2. –ù–∞–π—Ç–∏ –õ–£–ß–®–ò–ô –ø–∞—Ç—Ç–µ—Ä–Ω (—Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –≥—Ä—É–ø–ø)
        3. –ò–∑–≤–ª–µ—á—å –≥—Ä—É–ø–ø—É 'author' –∏–∑ –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞
        4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–º—è –∞–≤—Ç–æ—Ä–∞ (–∏—Å–ø–æ–ª—å–∑—É—è _contains_author_name)
        
        –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: –ü–∞—Ç—Ç–µ—Ä–Ω —Å 3+ –≥—Ä—É–ø–ø–∞–º–∏ (author, title, series) > –ø–∞—Ç—Ç–µ—Ä–Ω —Å 2 –≥—Ä—É–ø–ø–∞–º–∏ (author, title)
        
        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            
        Returns:
            –ò–º—è –∞–≤—Ç–æ—Ä–∞ –∏–ª–∏ None
        """
        if not filename or not self.author_patterns:
            return None
        
        # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        best_author = None
        best_group_count = 0
        
        # –ü–µ—Ä–µ–±—Ä–∞—Ç—å –í–°–ï –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –≤—ã–±—Ä–∞—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–π
        for pattern_dict in self.author_patterns:
            pattern_desc = pattern_dict.get('pattern', '')
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ –≤ regex
            regex_data = self._file_pattern_to_regex(pattern_desc)
            if not regex_data:
                continue
            
            regex_pattern, group_names = regex_data
            
            # –ü–æ–ø—ã—Ç–∞—Ç—å—Å—è —Å–æ–≤–ø—Ä–æ—Å—Ç–∏—Ç—å —Å –ø–∞—Ç—Ç–µ—Ä–Ω–æ–º
            try:
                match = re.match(regex_pattern, filename, re.IGNORECASE)
                if match:
                    # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ –≥—Ä—É–ø–ø —Å–æ–≤–ø–∞–¥–∞–ª–æ (—Å–∫–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑–≤–ª–µ–∫–ª–∏)
                    matched_groups = len([g for g in match.groups() if g is not None])
                    
                    # –ï—Å–ª–∏ —ç—Ç–æ –ª—É—á—à–µ —á–µ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ - –∑–∞–ø–æ–º–Ω–∏—Ç—å
                    if matched_groups > best_group_count:
                        author = match.group('author')
                        if author:
                            author = author.strip()
                            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–º—è –∞–≤—Ç–æ—Ä–∞
                            # –ü–†–ò–û–†–ò–¢–ï–¢: 1) –∏–∑–≤–µ—Å—Ç–Ω–æ–µ –∏–º—è, 2) –ø–æ—Ö–æ–∂–µ –Ω–∞ –∏–º—è –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
                            if self._contains_author_name(author) or self._looks_like_author_name(author):
                                best_author = author
                                best_group_count = matched_groups
            except Exception:
                # –ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º–∞ —Å regex - –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å —ç—Ç–æ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω
                continue
        
        return best_author
    
    def regenerate(self, output_csv: Optional[str] = None) -> bool:
        """–í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ CSV.
        
        Args:
            output_csv: –ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV —Ñ–∞–π–ª—É (–µ—Å–ª–∏ None - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç config)
            
        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –∏–Ω–∞—á–µ
        """
        try:
            print("\n" + "üöÄ "*40, flush=True)
            print("\n  üìä –†–ï–ì–ï–ù–ï–†–ê–¶–ò–Ø CSV - 6-PASS –°–ò–°–¢–ï–ú–ê", flush=True)
            print(f"  üìÅ –†–∞–±–æ—á–∞—è –ø–∞–ø–∫–∞: {self.work_dir}\n", flush=True)
            print("üöÄ "*40 + "\n", flush=True)
            
            self.logger.log("=== –ù–∞—á–∞–ª–æ —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ CSV ===")
            
            # PASS 1: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è - —á—Ç–µ–Ω–∏–µ FB2 —Ñ–∞–π–ª–æ–≤ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–æ–≤
            self._pass1_read_fb2_files()
            if not self.records:
                self.logger.log("‚ùå –ù–µ—Ç –Ω–∞–π–¥–µ–Ω–æ FB2 —Ñ–∞–π–ª–æ–≤")
                return False
            
            self.logger.log(f"‚úÖ PASS 1: –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(self.records)} —Ñ–∞–π–ª–æ–≤")
            
            # PASS 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–∞ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            self._pass2_extract_from_filename()
            self.logger.log(f"‚úÖ PASS 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤")
            
            # PASS 3: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –∞–≤—Ç–æ—Ä–æ–≤
            self._pass3_normalize_authors()
            self.logger.log(f"‚úÖ PASS 3: –ó–∞–≤–µ—Ä—à–µ–Ω–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∞–≤—Ç–æ—Ä–æ–≤")
            
            # PASS 4: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞
            self._pass4_apply_consensus()
            self.logger.log(f"‚úÖ PASS 4: –ó–∞–≤–µ—Ä—à–µ–Ω–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞")
            
            # PASS 5: –ü–µ—Ä–µ–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ conversions
            self._pass5_apply_conversions()
            self.logger.log(f"‚úÖ PASS 5: –ó–∞–≤–µ—Ä—à–µ–Ω–æ –ø–µ—Ä–µ–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ conversions")
            
            # PASS 6: –†–∞—Å–∫—Ä—ã—Ç–∏–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä
            self._pass6_expand_abbreviations()
            self.logger.log(f"‚úÖ PASS 6: –ó–∞–≤–µ—Ä—à–µ–Ω–æ —Ä–∞—Å–∫—Ä—ã—Ç–∏–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä")
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∞–≤—Ç–æ—Ä–æ–≤ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É –µ—Å–ª–∏ –∏—Ö –Ω–µ—Å–∫–æ–ª—å–∫–æ
            self._sort_authors_in_records()
            self.logger.log(f"‚úÖ –ê–≤—Ç–æ—Ä—ã –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É")
            
            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∑–∞–ø–∏—Å–µ–π: –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É, –ø–æ—Ç–æ–º –ø–∞–ø–∫–∏ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
            self._sort_records()
            self.logger.log(f"‚úÖ –ó–∞–ø–∏—Å–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã")
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ CSV
            csv_path = output_csv or self._get_output_csv_path()
            self._save_csv(csv_path)
            
            self.logger.log(f"‚úÖ CSV —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {csv_path}")
            self.logger.log("=== –†–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ ===")
            
            # –§–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
            print("="*80, flush=True)
            print("‚úÖ –†–ï–ì–ï–ù–ï–†–ê–¶–ò–Ø –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù–ê!", flush=True)
            print("="*80 + "\n", flush=True)
            
            return True
            
        except Exception as e:
            self.logger.log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _parse_author_from_folder_name(self, folder_name: str) -> str:
        """–†–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–∞–ø–∫–∏.
        
        –í–µ–∑–¥–µ –µ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç: "–Ω–∞–∑–≤–∞–Ω–∏–µ_—Å–µ—Ä–∏–∏ (–∞–≤—Ç–æ—Ä—ã)" –∏–ª–∏ "–Ω–∞–∑–≤–∞–Ω–∏–µ_—Å–µ—Ä–∏–∏ (–∞–≤—Ç–æ—Ä1, –∞–≤—Ç–æ—Ä2)"
        –ü—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–ª—É—á–∞–∏ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Å–∫–æ–±–∫–∞–º–∏:
        "–ú–í–ü-2 (1) –û–¥–∏—Å—Å–µ—è (–ê–ª–µ–∫—Å–∞–Ω–¥—Ä –ß–µ—Ä–Ω–æ–≤)" ‚Üí "–ê–ª–µ–∫—Å–∞–Ω–¥—Ä –ß–µ—Ä–Ω–æ–≤"
        
        –õ–æ–≥–∏–∫–∞:
        - –ï—Å–ª–∏ 1 –∞–≤—Ç–æ—Ä: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å
        - –ï—Å–ª–∏ 2 –∞–≤—Ç–æ—Ä–∞: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–æ–∏—Ö —á–µ—Ä–µ–∑ '; ' (–±—É–¥–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ PASS –ø–æ–∑–∂–µ)
        - –ï—Å–ª–∏ >2: –±–µ—Ä—ë–º –ø–µ—Ä–≤–æ–≥–æ
        
        –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ò–ú–Ø –∞–≤—Ç–æ—Ä–∞ (–Ω–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏/—Å–µ—Ä–∏–∏)
        
        Args:
            folder_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏
            
        Returns:
            –ò–º—è –∞–≤—Ç–æ—Ä–∞/–∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –ø–∞–ø–∫–∏, –∏–ª–∏ "" –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–º—è
        """
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—Å—Ç—å –ª–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ —Å–∫–æ–±–∫–∞—Ö
        # –ü–∞—Ç—Ç–µ—Ä–Ω: "–Ω–∞–∑–≤–∞–Ω–∏–µ (—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ)" - –∏—â–µ—Ç –ü–û–°–õ–ï–î–ù–ò–ï —Å–∫–æ–±–∫–∏ –≤ —Å—Ç—Ä–æ–∫–µ
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º [^)]* —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å –≤–ª–æ–∂–µ–Ω–Ω—ã–º–∏ —Å–∫–æ–±–∫–∞–º–∏
        match = re.search(r'\(([^)]*)\)$', folder_name)
        
        if match:
            # –ï—Å—Ç—å —Å–∫–æ–±–∫–∏ —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º
            content = match.group(1)  # "–ê.–ú–∏—Ö–∞–π–ª–æ–≤—Å–∫–∏–π, –ê.–•–∞—Ä–Ω–∏–∫–æ–≤" –∏–ª–∏ "–ë—É–ª–∞–Ω–æ–≤ –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω"
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–º—è –∞–≤—Ç–æ—Ä–∞
            if not self._contains_author_name(content):
                # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ —Å–∫–æ–±–∫–∞—Ö - –Ω–µ –∏–º—è –∞–≤—Ç–æ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä "(1)" –∏–ª–∏ "(2021)")
                # –í–µ—Ä–Ω—ë–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É —á—Ç–æ–±—ã –æ–±–æ–π—Ç–∏ —ç—Ç—É –ø–∞–ø–∫—É
                return ""
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–æ–≤ —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã—Ö –∑–∞–ø—è—Ç–æ–π
            if ',' in content:
                # –†–∞–∑–±–∏—Ç—å –Ω–∞ –∞–≤—Ç–æ—Ä–æ–≤
                authors = [a.strip() for a in content.split(',')]
                
                if len(authors) <= 2:
                    # <= 2 –∞–≤—Ç–æ—Ä–æ–≤ - –±–µ—Ä—ë–º –≤—Å–µ—Ö —á–µ—Ä–µ–∑ '; ' (–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –¥–ª—è PASS)
                    return '; '.join(authors)
                else:
                    # > 2 –∞–≤—Ç–æ—Ä–æ–≤ - –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–≥–æ
                    return authors[0]
            
            # –ò–Ω–∞—á–µ –ø—Ä–æ—Å—Ç–æ –æ–¥–∏–Ω –∞–≤—Ç–æ—Ä –≤ —Å–∫–æ–±–∫–∞—Ö
            return content.strip()
        
        # –ù–µ—Ç —Å–∫–æ–±–æ–∫ - —ç—Ç–æ –æ–±—ã—á–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏/—Å–µ—Ä–∏–∏, –Ω–µ –∏–º—è –∞–≤—Ç–æ—Ä–∞
        # –ü—Ä–æ–≤–µ—Ä–∏–ª–∏ - –µ—Å–ª–∏ —ç—Ç–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–º—è –∞–≤—Ç–æ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º, –∏–Ω–∞—á–µ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        if self._contains_author_name(folder_name):
            # –ú–æ–∂–µ—Ç –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ "–ò–º—è –§–∞–º–∏–ª–∏—è" –±–µ–∑ —Å–∫–æ–±–æ–∫
            return folder_name
        
        # –ù–µ –∏–º—è - –ø—Ä–æ—Å—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏/—Å–µ—Ä–∏–∏
        return ""
    
    def _clean_author_name(self, author_str: str) -> str:
        """–û—á–∏—Å—Ç–∏—Ç—å –∏–º—è –∞–≤—Ç–æ—Ä–∞ –æ—Ç –ø–∞—Ä–∞–∑–∏—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤.
        
        –£–¥–∞–ª—è–µ—Ç:
        - –¢–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏
        - –°–∫–æ–±–∫–∏ –∏ –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ (–∫—Ä–æ–º–µ —Å–∫–æ–±–æ–∫ –≤ —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö –∏–º–µ–Ω–∞—Ö)
        - –ö–∞–≤—ã—á–∫–∏ –≤ –Ω–∞—á–∞–ª–µ/–∫–æ–Ω—Ü–µ
        - –õ–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        - –ó–∞–ø—è—Ç—ã–µ –≤ –∫–æ–Ω—Ü–µ
        
        Args:
            author_str: –°—Ç—Ä–æ–∫–∞ —Å –∏–º–µ–Ω–µ–º –∞–≤—Ç–æ—Ä–∞
            
        Returns:
            –û—á–∏—â–µ–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
        """
        if not author_str:
            return ""
        
        try:
            # –£–±–µ—Ä—ë–º –∫–∞–≤—ã—á–∫–∏ –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
            author_str = author_str.strip('¬´¬ª"\'')
            
            # –£–±–µ—Ä—ë–º —Å–∫–æ–±–∫–∏ —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º (–¥–ª—è —Å–ª—É—á–∞–µ–≤ —Ç–∏–ø–∞ "(–õ–µ–≥–∏–æ–Ω –ñ–∏–≤–æ–π,")
            # –ù–æ –±—É–¥–µ–º –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã - –æ—Å—Ç–∞–≤–ª—è–µ–º —Å–∫–æ–±–∫–∏ –µ—Å–ª–∏ —ç—Ç–æ —Å–æ—Å—Ç–∞–≤–Ω–æ–µ –∏–º—è –≤—Ä–æ–¥–µ "–ê.–í. (—Å–æ—Å—Ç–∞–≤–Ω–æ–µ)"
            author_str = re.sub(r'\s*\([^)]*\)\s*', ' ', author_str)
            
            # –£–±–µ—Ä—ë–º —Ç–æ—á–∫—É –≤ –∫–æ–Ω—Ü–µ (–¥–ª—è "–ú–µ—Ç–µ–ª—å—Å–∫–∏–π." ‚Üí "–ú–µ—Ç–µ–ª—å—Å–∫–∏–π")
            author_str = re.sub(r'\.$', '', author_str)
            
            # –£–±–µ—Ä—ë–º –∑–∞–ø—è—Ç—É—é –≤ –∫–æ–Ω—Ü–µ (–¥–ª—è —Å–ª—É—á–∞–µ–≤ —Ç–∏–ø–∞ "–ù–∏–∫–æ–ª–∞–µ–≤ –ó–ª–æ—Ç–Ω–∏–∫–æ–≤,")
            author_str = re.sub(r',$', '', author_str)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã (–Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª–æ–≤ ‚Üí –æ–¥–∏–Ω)
            author_str = re.sub(r'\s+', ' ', author_str)
            
            return author_str.strip()
        except Exception:
            return author_str
    
    def _process_and_expand_authors(self, cleaned_author: str, current_record, all_records) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞–≤—Ç–æ—Ä–æ–≤: —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ø–æ –∑–∞–ø—è—Ç—ã–º, —Ä–∞—Å—à–∏—Ä–∏—Ç—å, —É–±—Ä–∞—Ç—å –¥—É–±–ª–∏.
        
        –ê–ª–≥–æ—Ä–∏—Ç–º:
        1. –£–±—Ä–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –∏—Å—Ö–æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä "–ê–≤—Ç–æ—Ä, –ê–≤—Ç–æ—Ä" ‚Üí "–ê–≤—Ç–æ—Ä")
        2. –†–∞–∑–±–∏—Ç—å –ø–æ –∑–∞–ø—è—Ç—ã–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤
        3. –î–ª—è –∫–∞–∂–¥–æ–≥–æ: —Ä–∞—Å—à–∏—Ä–∏—Ç—å –∏–∑ metadata —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
        4. –ï—Å–ª–∏ –Ω–µ —Ä–∞—Å—à–∏—Ä–∏–ª–æ—Å—å - –∏—Å–∫–∞—Ç—å –≤ metadata —Å–æ—Å–µ–¥–Ω–∏—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ —Ç–æ–π –∂–µ –ø–∞–ø–∫–∏
        5. –£–±—Ä–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –∞–≤—Ç–æ—Ä–æ–≤ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ
        6. –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Å "; " —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º
        
        Args:
            cleaned_author: –û—á–∏—â–µ–Ω–Ω–æ–µ –∏–º—è/–∏–º–µ–Ω–∞ –∞–≤—Ç–æ—Ä–æ–≤ (–º–æ–∂–µ—Ç –±—ã—Ç—å "–ê–≤—Ç–æ—Ä1, –ê–≤—Ç–æ—Ä2")
            current_record: –¢–µ–∫—É—â–∏–π CV record —Å metadata_authors
            all_records: –í—Å–µ records –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ —Å–æ—Å–µ–¥–Ω–∏—Ö —Ñ–∞–π–ª–∞—Ö
            
        Returns:
            –§–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è –∞–≤—Ç–æ—Ä–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ "–§–ò" –∏–ª–∏ "–§–ò; –§–ò"
        """
        if not cleaned_author:
            return ""
        
        # –®–∞–≥ 0: –£–±—Ä–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –∏—Å—Ö–æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä "–ê–≤—Ç–æ—Ä, –ê–≤—Ç–æ—Ä, –ê–≤—Ç–æ—Ä")
        # –†–∞–∑–±–∏–≤–∞–µ–º, —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏, –∏ –∑–∞–Ω–æ–≤–æ –æ–±—ä–µ–¥–∏–Ω—è–µ–º
        initial_parts = [a.strip() for a in cleaned_author.split(',') if a.strip()]
        seen_initial = set()
        unique_initial = []
        for part in initial_parts:
            if part not in seen_initial:
                unique_initial.append(part)
                seen_initial.add(part)
        
        if len(unique_initial) < len(initial_parts):
            # –ë—ã–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ –∏—Å—Ö–æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–µ - –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—á–∏—â–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
            cleaned_author = ", ".join(unique_initial)
        
        # –®–∞–≥ 1: –†–∞–∑–±–∏—Ç—å –ø–æ –∑–∞–ø—è—Ç—ã–º –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–æ–≤
        author_parts = [a.strip() for a in cleaned_author.split(',') if a.strip()]
        
        # –®–∞–≥ 2: –†–∞—Å—à–∏—Ä–∏—Ç—å –∫–∞–∂–¥–æ–≥–æ –∞–≤—Ç–æ—Ä–∞
        expanded_parts = []
        for part in author_parts:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Ä–∞—Å—à–∏—Ä–∏—Ç—å –∏–∑ metadata —Ç–µ–∫—É—â–µ–≥–æ —Ñ–∞–π–ª–∞
            expanded = self._expand_author_to_full_name(part, current_record.metadata_authors or "")
            
            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –∏ —ç—Ç–æ –æ–¥–Ω–æ —Å–ª–æ–≤–æ (—Ñ–∞–º–∏–ª–∏—è) - –∏—â–µ–º –≤ —Å–æ—Å–µ–¥–Ω–∏—Ö —Ñ–∞–π–ª–∞—Ö
            if expanded == part and len(part.split()) == 1:  # –ù–µ —Ä–∞—Å—à–∏—Ä–∏–ª–æ—Å—å
                # –ò—â–µ–º –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–æ–≤ –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ –∏–ª–∏ –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö—Å—è —Å —ç—Ç–æ–≥–æ –∞–≤—Ç–æ—Ä–∞
                current_dir = str(Path(current_record.file_path).parent)
                
                for other_record in all_records:
                    if other_record.file_path == current_record.file_path:
                        continue  # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Å–∞–º —Å–µ–±—è
                    
                    other_dir = str(Path(other_record.file_path).parent)
                    
                    # –ï—Å–ª–∏ —Ñ–∞–π–ª—ã –≤ –æ–¥–Ω–æ–π –ø–∞–ø–∫–µ - –ø—Ä–æ–±—É–µ–º –µ–≥–æ metadata
                    if other_dir == current_dir and other_record.metadata_authors:
                        found = self._expand_author_to_full_name(part, other_record.metadata_authors)
                        if found != part:  # –ù–∞—à–ª–∏!
                            expanded = found
                            break
            
            if expanded:
                expanded_parts.append(expanded)
        
        # –®–∞–≥ 3: –£–±—Ä–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã –∞–≤—Ç–æ—Ä–æ–≤, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
        unique_authors = []
        seen = set()
        for author in expanded_parts:
            if author not in seen:
                unique_authors.append(author)
                seen.add(author)
        
        # –®–∞–≥ 3.5: –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∞–≤—Ç–æ—Ä–æ–≤ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
        unique_authors.sort()
        
        # –®–∞–≥ 4: –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º "; "
        if not unique_authors:
            return cleaned_author
        
        return "; ".join(unique_authors)
    
    def _expand_author_to_full_name(self, partial_author: str, metadata_authors: str) -> str:
        """–†–∞—Å—à–∏—Ä–∏—Ç—å partial author name –¥–æ –ø–æ–ª–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ "–§–∞–º–∏–ª–∏—è –ò–º—è" –∏—Å–ø–æ–ª—å–∑—É—è metadata.
        
        –õ–æ–≥–∏–∫–∞:
        - –ï—Å–ª–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ (—Ç–æ–ª—å–∫–æ —Ñ–∞–º–∏–ª–∏—è) ‚Üí –Ω–∞–π—Ç–∏ –≤ metadata –∏ –≤–µ—Ä–Ω—É—Ç—å –ø–æ–ª–Ω–æ–µ –∏–º—è
        - –ï—Å–ª–∏ 2 —Å–ª–æ–≤–∞ ‚Üí –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ —Å metadata author. –ï—Å–ª–∏ –Ω–µ—Ç ‚Üí –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è —Ä–∞–∑–æ–±—Ä–∞—Ç—å –∫–∞–∫ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–æ–≤
        - –ï—Å–ª–∏ 2+ —Å–ª–æ–≤–∞ –∏ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å metadata ‚Üí –≤–µ—Ä–Ω—É—Ç—å –∫–∞–∫ –µ—Å—Ç—å
        
        Args:
            partial_author: –ò–∑–≤–ª–µ—á—ë–Ω–Ω–æ–µ –∏–º—è –∞–≤—Ç–æ—Ä–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å incomplete)
            metadata_authors: –ü–æ–ª–Ω—ã–µ –∞–≤—Ç–æ—Ä—ã –∏–∑ metadata FB2
            
        Returns:
            –ü–æ–ª–Ω–æ–µ –∏–º—è –≤ —Ñ–æ—Ä–º–∞—Ç–µ "–§–∞–º–∏–ª–∏—è –ò–º—è"
        """
        if not partial_author or not metadata_authors:
            return partial_author
        
        try:
            words = partial_author.split()
            metadata_authors_list = [a.strip() for a in re.split(r'[;,]', metadata_authors) if a.strip()]
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –û–¥–Ω–æ —Å–ª–æ–≤–æ - —ç—Ç–æ —Ñ–∞–º–∏–ª–∏—è, –Ω–∞–π—Ç–∏ –ø–æ–ª–Ω–æ–µ –∏–º—è –≤ metadata
            if len(words) == 1:
                surname = words[0]
                matching_authors = []  # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ—Ö –∞–≤—Ç–æ—Ä–æ–≤ —Å —ç—Ç–æ–π —Ñ–∞–º–∏–ª–∏–µ–π
                
                for full_name in metadata_authors_list:
                    full_lower = full_name.lower()
                    surname_lower = surname.lower()
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –∫–æ–Ω—Ü–µ (–æ–±—ã—á–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –§–∞–º–∏–ª–∏—è –ò–º—è)
                    if full_lower.endswith(surname_lower) or full_lower.startswith(surname_lower):
                        matching_authors.append(full_name)
                    # –ò–ª–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ñ–∞–º–∏–ª–∏—è –ø—Ä—è–º–æ –≤ –∏–º–µ–Ω–∏
                    elif surname_lower in full_lower.split():
                        matching_authors.append(full_name)
                
                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –∞–≤—Ç–æ—Ä–æ–≤ - –≤–µ—Ä–Ω—É—Ç—å –∏—Ö
                if matching_authors:
                    if len(matching_authors) == 1:
                        return matching_authors[0]
                    else:
                        # –ù–µ—Å–∫–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–æ–≤ —Å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–π —Ñ–∞–º–∏–ª–∏–µ–π
                        # –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –∏ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —á–µ—Ä–µ–∑ "; "
                        matching_authors.sort()
                        return "; ".join(matching_authors)
                
                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ - –≤–µ—Ä–Ω—É—Ç—å –∫–∞–∫ –µ—Å—Ç—å
                return partial_author
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –ù–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤ - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ —Å metadata
            if len(words) >= 2:
                partial_lower = partial_author.lower()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–≤–ø–∞–¥–∞–µ—Ç –ª–∏ —ç—Ç–æ —Å –æ–¥–Ω–∏–º –∏–∑ metadata authors
                for full_name in metadata_authors_list:
                    full_lower = full_name.lower()
                    full_name_words = full_name.split()
                    
                    # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ?
                    if partial_lower == full_lower:
                        return partial_author
                    
                    # –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä–∫–∞ –µ—Å–ª–∏ –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ —Å–ª–æ–≤–∞ –≤ —Ä–∞–∑–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ?
                    # (–Ω–∞–ø—Ä–∏–º–µ—Ä "–¢—ë –ò–ª—å—è" vs "–ò–ª—å—è –¢—ë" - –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ —Å–ª–æ–≤–∞)
                    partial_words_set = set(w.lower() for w in words)
                    full_name_words_set = set(w.lower() for w in full_name_words)
                    if (len(words) == len(full_name_words) and 
                        partial_words_set == full_name_words_set):
                        # –û–¥–Ω–∏ –∏ —Ç–µ –∂–µ —Å–ª–æ–≤–∞, —Ç–æ–ª—å–∫–æ –≤ —Ä–∞–∑–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
                        # –ü–æ—Å–∫–æ–ª—å–∫—É filename –æ–±—ã—á–Ω–æ –Ω–∞–¥—ë–∂–Ω–µ–µ metadata, –æ—Å—Ç–∞–≤–ª—è–µ–º partial_author
                        return partial_author
                    
                    # –ú–æ–∂–µ—Ç –±—ã—Ç—å —ç—Ç–æ –æ–±—Ä–∞—Ç–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫? (–ñ–∏–≤–æ–π –ê–ª–µ–∫—Å–µ–π vs –ê–ª–µ–∫—Å–µ–π –ñ–∏–≤–æ–π)
                    if partial_author in full_name or full_name in partial_author:
                        # –í–ê–ñ–ù–û: –µ—Å–ª–∏ partial_author —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (–±–æ–ª—å—à–µ —Å–ª–æ–≤),
                        # —á–µ–º full_name, —Ç–æ –æ—Å—Ç–∞–≤–∏—Ç—å partial_author –∫–∞–∫ –±–æ–ª–µ–µ –ø–æ–ª–Ω—É—é –≤–µ—Ä—Å–∏—é
                        # –ü—Ä–∏–º–µ—Ä: partial="–ò–≤–∞–Ω–æ–≤ –î–º–∏—Ç—Ä–∏–π", full_name="–î–º–∏—Ç—Ä–∏–π"
                        # –ò–≤–∞–Ω–æ–≤ –î–º–∏—Ç—Ä–∏–π —Å–æ–¥–µ—Ä–∂–∏—Ç –î–º–∏—Ç—Ä–∏–π, –Ω–æ –∏–º–µ–µ—Ç –±–æ–ª—å—à–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                        if len(words) > len(full_name_words):
                            return partial_author  # –ë–æ–ª–µ–µ –ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏–∑ filename
                        else:
                            return full_name  # –ë–æ–ª–µ–µ –ø–æ–ª–Ω–∞—è –≤–µ—Ä—Å–∏—è –∏–∑ metadata
                
                # –ï—Å–ª–∏ —ç—Ç–æ 2 —Å–ª–æ–≤–∞ –Ω–æ –ù–ï —Å–æ–≤–ø–∞–¥–∞–µ—Ç –Ω–∏ —Å –æ–¥–Ω–∏–º metadata author,
                # —ç—Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ –ù–ï–°–ö–û–õ–¨–ö–û –∞–≤—Ç–æ—Ä–æ–≤ (—Ç–∏–ø–∞ "–ü—Ä–æ–∑–æ—Ä–æ–≤ –ñ–∏–≤–æ–π" = –∞–≤—Ç–æ—Ä1 + –∞–≤—Ç–æ—Ä2)
                # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –∫–∞–∫ –æ—Ç–¥–µ–ª—å–Ω—É—é —Ñ–∞–º–∏–ª–∏—é
                if len(words) == 2:
                    found_authors = []
                    for word in words:
                        for full_name in metadata_authors_list:
                            full_lower = full_name.lower()
                            word_lower = word.lower()
                            # –ò—â–µ–º —ç—Ç–æ —Å–ª–æ–≤–æ –≤ metadata authors
                            if full_lower.endswith(word_lower) or full_lower.startswith(word_lower) or word_lower in full_lower.split():
                                found_authors.append(full_name)
                                break
                    
                    # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ 2 –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –∞–≤—Ç–æ—Ä–∞ - –≤–µ—Ä–Ω—É—Ç—å –æ–¥–Ω–æ–≥–æ
                    if len(found_authors) == 2:
                        if found_authors[0] == found_authors[1]:
                            return found_authors[0]
                        else:
                            return "; ".join(found_authors)
                    elif len(found_authors) == 1:
                        # –ù–∞—à–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ–≥–æ –∏–∑ –¥–≤—É—Ö - –≤–µ—Ä–Ω—É—Ç—å –µ–≥–æ
                        return found_authors[0]
                
                # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–æ–≤–ø–∞–ª–æ - –≤–µ—Ä–Ω—É—Ç—å –∫–∞–∫ –µ—Å—Ç—å
                return partial_author
            
            return partial_author
        except Exception:
            return partial_author
    
    def _build_folder_structure(self) -> Dict[Path, str]:
        """–ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–≤—Ç–æ—Ä—Å–∫–∏–µ –ø–∞–ø–∫–∏.
        
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–µ—Ä–∞—Ä—Ö–∏—é –ø–∞–ø–æ–∫ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–∏–µ –ø–∞–ø–∫–∏ —è–≤–ª—è—é—Ç—Å—è –∞–≤—Ç–æ—Ä—Å–∫–∏–º–∏
        (—Å–æ–¥–µ—Ä–∂–∞—Ç –∫–Ω–∏–≥–∏ –æ–¥–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä–∞). –ò—â–µ—Ç –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω—è—Ö –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏.
        
        Returns:
            Dict[Path, str]: –°–ª–æ–≤–∞—Ä—å {–ø–∞–ø–∫–∞_–ø—É—Ç—å: –∏–º—è_–∞–≤—Ç–æ—Ä–∞}
        """
        folder_authors = {}
        blacklist = self.settings.get_filename_blacklist()
        
        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å–∫–∞–Ω –ø–∞–ø–æ–∫ –¥–æ –Ω—É–∂–Ω–æ–π –≥–ª—É–±–∏–Ω—ã (2-3 —É—Ä–æ–≤–Ω—è)
        # –ù—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –ø–∞–ø–∫–∏ —Ç–∏–ø–∞ "–ê–≤—Ç–æ—Ä –§–∞–º–∏–ª–∏—è" –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω—è—Ö
        def scan_folder(folder_path: Path, depth: int = 0, max_depth: int = 3):
            if depth > max_depth:
                return
            
            try:
                for folder in folder_path.iterdir():
                    if folder.is_dir():
                        folder_name = folder.name
                        
                        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å: —ç—Ç–æ –∞–≤—Ç–æ—Ä—Å–∫–∞—è –ø–∞–ø–∫–∞?
                        is_blacklisted = any(word.lower() in folder_name.lower() for word in blacklist)
                        
                        if not is_blacklisted:
                            # –≠—Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ –∞–≤—Ç–æ—Ä—Å–∫–∞—è –ø–∞–ø–∫–∞
                            # –ü–∞—Ä—Å–∏–º –∏–º—è –∞–≤—Ç–æ—Ä–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏)
                            author_name = self._parse_author_from_folder_name(folder_name)
                            folder_authors[folder] = author_name
                            
                            parsed_name = author_name if not is_blacklisted else '[–∏—Å–∫–ª—é—á–µ–Ω–∞]'
                            self.logger.log(f"[–°—Ç—Ä—É–∫—Ç—É—Ä–∞ {depth}] –ü–∞–ø–∫–∞: {folder_name} ‚Üí –∞–≤—Ç–æ—Ä: {parsed_name}")
                        
                        # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —Å–º–æ—Ç—Ä–∏–º –ø–æ–¥–ø–∞–ø–∫–∏ (–Ω–æ –Ω–µ –æ—á–µ–Ω—å –≥–ª—É–±–æ–∫–æ)
                        if depth < max_depth:
                            scan_folder(folder, depth + 1, max_depth)
            except Exception as e:
                self.logger.log(f"[–°—Ç—Ä—É–∫—Ç—É—Ä–∞] –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ {folder_path}: {e}")
        
        # –ù–∞—á–∏–Ω–∞–µ–º —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å work_dir
        scan_folder(self.work_dir, depth=0, max_depth=2)
        
        return folder_authors
    
    def _get_author_for_file(self, fb2_file: Path, folder_authors: Dict[Path, str]) -> tuple:
        """–û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–≤—Ç–æ—Ä–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏—Å–ø–æ–ª—å–∑—É—è —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫.
        
        –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
        1. –ï—Å–ª–∏ —Ñ–∞–π–ª –≤ –∞–≤—Ç–æ—Ä—Å–∫–æ–π –ø–∞–ø–∫–µ ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–≤—Ç–æ—Ä–∞ –∏–∑ –ø–∞–ø–∫–∏ (folder_dataset)
        2. –ò–Ω–∞—á–µ ‚Üí –≤—ã–∑–≤–∞–µ–º resolve_author_by_priority (–ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ filename –∏ metadata)
        
        Args:
            fb2_file: –ø—É—Ç—å –∫ FB2 —Ñ–∞–π–ª—É
            folder_authors: —Å–ª–æ–≤–∞—Ä—å –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –ø–∞–ø–æ–∫ –∏–∑ _build_folder_structure()
            
        Returns:
            (author, source) –≥–¥–µ source in ['folder_dataset', 'filename', 'metadata', '']
        """
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å: –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –≤ –∞–≤—Ç–æ—Ä—Å–∫–æ–π –ø–∞–ø–∫–µ?
        for author_folder, author_name in folder_authors.items():
            try:
                # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å: fb2_file –≤ –ø–∞–ø–∫–µ author_folder?
                fb2_file.relative_to(author_folder)
                # –î–∞! –§–∞–π–ª –≤ –∞–≤—Ç–æ—Ä—Å–∫–æ–π –ø–∞–ø–∫–µ
                
                # –ü—Ä–∏–º–µ–Ω–∏—Ç—å conversions –∫ –∏–º–µ–Ω–∏ –∞–≤—Ç–æ—Ä–∞ –∏–∑ –ø–∞–ø–∫–∏
                author_name_converted = author_name
                conversions = self.settings.get_author_surname_conversions()
                if author_name in conversions:
                    author_name_converted = conversions[author_name]
                
                return author_name_converted, 'folder_dataset'
            except ValueError:
                # –ù–µ—Ç, –Ω–µ –≤ —ç—Ç–æ–π –ø–∞–ø–∫–µ
                continue
        
        # –§–∞–π–ª –Ω–µ –≤ –∞–≤—Ç–æ—Ä—Å–∫–æ–π –ø–∞–ø–∫–µ ‚Üí –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—ã—á–Ω—É—é –ª–æ–≥–∏–∫—É
        author, source = self.extractor.resolve_author_by_priority(
            str(fb2_file),
            folder_parse_limit=self.folder_parse_limit
        )
        
        return author, source
    
    def _pass1_read_fb2_files(self) -> None:
        """PASS 1: –ß—Ç–µ–Ω–∏–µ FB2 —Ñ–∞–π–ª–æ–≤ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–æ–≤ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É.
        
        –ê–ª–≥–æ—Ä–∏—Ç–º:
        1. –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ª–æ–≥–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ —Å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –ø–∞–ø–æ–∫
        2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Ñ–æ –æ–± –∞–≤—Ç–æ—Ä—Å–∫–æ–π –ø–∞–ø–∫–µ
        3. –ï—Å–ª–∏ —Ñ–∞–π–ª –≤ –∞–≤—Ç–æ—Ä—Å–∫–æ–π –ø–∞–ø–∫–µ ‚Üí author_source = "folder_dataset"
        4. –ï—Å–ª–∏ —Ñ–∞–π–ª –≤–Ω–µ –∞–≤—Ç–æ—Ä—Å–∫–æ–π –ø–∞–ø–∫–∏ ‚Üí –ø—Ä–æ–±–æ–≤–∞—Ç—å filename ‚Üí metadata
        """
        print("\n" + "="*80, flush=True)
        print("üîÑ PASS 1: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ FB2 —Ñ–∞–π–ª–æ–≤...", flush=True)
        print("="*80, flush=True)
        
        self.logger.log("[PASS 1] –ù–∞—á–∞–ª–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è FB2 —Ñ–∞–π–ª–æ–≤...")
        
        # –®–∞–≥ 1: –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø–∞–ø–æ–∫ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –ø–∞–ø–æ–∫
        folder_authors = self._build_folder_structure()
        
        fb2_count = 0
        error_count = 0
        
        for fb2_file in self.work_dir.rglob('*.fb2'):
            try:
                # –ü–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–±–æ—á–µ–π –ø–∞–ø–∫–∏ (work_dir)
                rel_path = fb2_file.relative_to(self.work_dir)
                
                fb2_count += 1
                # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 5 –∏ –∫–∞–∂–¥—ã–π 50-–π —Ñ–∞–π–ª
                if fb2_count <= 5 or fb2_count % 50 == 0:
                    print(f"  [{fb2_count:4d}] {rel_path}", flush=True)
                
                # –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–≤—Ç–æ—Ä–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                author, source = self._get_author_for_file(fb2_file, folder_authors)
                
                # –ò–∑–≤–ª–µ—á—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö FB2
                title = self.extractor._extract_title_from_fb2(fb2_file)
                
                # –ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ—Ö –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–≤—Å–µ –∞–≤—Ç–æ—Ä—ã –∏–∑ <title-info>)
                metadata_authors = self.extractor._extract_all_authors_from_metadata(fb2_file)
                
                # TODO: –ò–∑–≤–ª–µ—á—å —Å–µ—Ä–∏—é –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö FB2 (–ø–æ–∫–∞ –ø—É—Å—Ç–æ)
                metadata_series = ""
                
                # –°–æ–∑–¥–∞—Ç—å BookRecord
                record = BookRecord(
                    file_path=str(rel_path),
                    file_title=title or "[–±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è]",
                    metadata_authors=metadata_authors or "[–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ]",
                    proposed_author=author or "–°–±–æ—Ä–Ω–∏–∫",
                    author_source=source or "metadata",
                    metadata_series=metadata_series,
                    proposed_series=metadata_series,  # –ù–∞ PASS 1 = metadata (–ø–æ–∫–∞ –ø—É—Å—Ç–æ)
                    series_source=""  # –ù–∞ PASS 1: series –Ω–µ –∑–∞–ø–æ–ª–Ω—è–µ—Ç—Å—è (–Ω–µ—Ç –ª–æ–≥–∏–∫–∏)
                )
                
                self.records.append(record)
                
                if fb2_count % 100 == 0:
                    self.logger.log(f"  [PASS 1] –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {fb2_count} —Ñ–∞–π–ª–æ–≤...")
                
            except Exception as e:
                error_count += 1
                self.logger.log(f"‚ö†Ô∏è  [PASS 1] –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {fb2_file}: {e}")
        
        print(f"\n‚úÖ PASS 1 –∑–∞–≤–µ—Ä—à—ë–Ω: –ø—Ä–æ—á–∏—Ç–∞–Ω–æ {fb2_count} —Ñ–∞–π–ª–æ–≤ (–æ—à–∏–±–æ–∫: {error_count})\n", flush=True)
        self.logger.log(f"[PASS 1] –ü—Ä–æ—á–∏—Ç–∞–Ω–æ {fb2_count} —Ñ–∞–π–ª–æ–≤ (–æ—à–∏–±–æ–∫: {error_count})")
    
    def _pass2_extract_from_filename(self) -> None:
        """PASS 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤/–ø–∞–ø–æ–∫ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
        
        –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ü–∞–ø–∫–∏ –ø–∞—Ä—Å—è—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –∏ –∫–µ—à–∏—Ä—É—é—Ç—Å—è –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –≤–Ω—É—Ç—Ä–∏ –Ω–∏—Ö.
        
        –î–ª—è —Ñ–∞–π–ª–æ–≤, –Ω–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã—Ö –≤ PASS 1 (–Ω–µ folder_dataset):
        1. –ò—â–µ–º –∞–≤—Ç–æ—Ä–∞ –≤ —Å–∫–æ–±–∫–∞—Ö –≤ –ø—É—Ç–∏ —Ñ–∞–π–ª–∞
        2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å–ª–∏ —ç—Ç–æ —Å–±–æ—Ä–Ω–∏–∫ (–º–∞—Ä–∫–µ—Ä—ã –≤ –∏–º–µ–Ω–∏ + –∞–≤—Ç–æ—Ä–æ–≤ > 2)
        3. –ï—Å–ª–∏ —Å–±–æ—Ä–Ω–∏–∫ - —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º "–°–±–æ—Ä–Ω–∏–∫", –∏–Ω–∞—á–µ –ø—Ä–∏–º–µ–Ω—è–µ–º –∏–∑–≤–ª–µ—á—ë–Ω–Ω–æ–≥–æ –∞–≤—Ç–æ—Ä–∞
        
        –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã —Å author_source="folder_dataset" - –æ–Ω–∏ —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã.
        """
        print("\n" + "="*80, flush=True)
        print("üìÑ PASS 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤ –∏ –ø–∞–ø–æ–∫...", flush=True)
        print("="*80, flush=True)
        
        self.logger.log("[PASS 2] –ù–∞—á–∞–ª–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –∏–º—ë–Ω —Ñ–∞–π–ª–æ–≤/–ø–∞–ø–æ–∫...")
        
        # –ö–ï–®–ò–†–û–í–ê–ù–ò–ï –ü–ê–ü–û–ö: –î–ª—è –∫–∞–∂–¥–æ–π —É–Ω–∏–∫–∞–ª—å–Ω–æ–π –ø–∞–ø–∫–∏ –ø–∞—Ä—Å–∏–º –æ–¥–∏–Ω —Ä–∞–∑
        # –ö–ª—é—á: –ø–æ–ª–Ω—ã–π –ø—É—Ç—å –ø–∞–ø–∫–∏, –ó–Ω–∞—á–µ–Ω–∏–µ: –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π –∞–≤—Ç–æ—Ä
        folder_cache = {}
        
        extracted_count = 0
        collection_count = 0
        
        for record in self.records:
            # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å —Ñ–∞–π–ª—ã —Å folder_dataset - –æ–Ω–∏ —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –Ω–∞–¥—ë–∂–Ω–æ
            if record.author_source == "folder_dataset":
                continue
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—Å–ª–∏ —ç—Ç–æ —Å–±–æ—Ä–Ω–∏–∫ –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            file_name = Path(record.file_path).stem  # –∏–º—è —Ñ–∞–π–ª–∞ –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
            
            # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–≤—Ç–æ—Ä–æ–≤ –≤ metadata
            author_count = 0
            if record.metadata_authors and record.metadata_authors not in ("–°–±–æ—Ä–Ω–∏–∫", "[–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ]"):
                # –°—á–∏—Ç–∞–µ–º –∞–≤—Ç–æ—Ä–æ–≤ (—Ä–∞–∑–¥–µ–ª–µ–Ω—ã –Ω–∞ ; –∏–ª–∏ ,)
                author_count = max(
                    record.metadata_authors.count(';') + 1,
                    record.metadata_authors.count(',') + 1
                )
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—Å–ª–∏ —Ñ–∞–π–ª - —Å–±–æ—Ä–Ω–∏–∫
            if self.extractor.is_anthology(file_name, author_count):
                record.proposed_author = "–°–±–æ—Ä–Ω–∏–∫"
                record.author_source = "filename"
                collection_count += 1
                continue
            
            # –ù–µ —Å–±–æ—Ä–Ω–∏–∫ - –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –Ω–∞–π—Ç–∏ –∞–≤—Ç–æ—Ä–∞ –≤ –ø—É—Ç–∏ —Ñ–∞–π–ª–∞
            # –ü–†–ò–û–†–ò–¢–ï–¢: –∏–º—è_—Ñ–∞–π–ª–∞ ‚Üí –ø–∞–ø–∫–∏
            
            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–∑–≤–ª–µ—á—å –∏–∑ –ò–ú–ï–ù–ò –§–ê–ô–õ–ê –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
            extracted_author = self._extract_author_from_filename_by_patterns(file_name)
            
            if extracted_author:
                # –£—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ–∫–ª–∏ –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
                # –®–∞–≥ 1: –û—á–∏—Å—Ç–∏—Ç—å –æ—Ç –ø–∞—Ä–∞–∑–∏—Ç–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                cleaned_author = self._clean_author_name(extracted_author)
                
                # –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–æ–≤ –∏ —É–±—Ä–∞—Ç—å –¥—É–±–ª–∏–∫–∞—Ç—ã
                final_author = self._process_and_expand_authors(cleaned_author, record, self.records)
                
                record.proposed_author = final_author
                record.author_source = "filename"
                extracted_count += 1
                continue
            
            # –ï—Å–ª–∏ –≤ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –Ω–µ –Ω–∞—à–ª–æ—Å—å - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–∞–ø–∫–∏
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ–¥–Ω–æ–π –ø–∞–ø–∫–∏
            file_path = Path(record.file_path)
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Å–µ —á–∞—Å—Ç–∏ –ø—É—Ç–∏, –Ω–∞—á–∏–Ω–∞—è —Å —Å–∞–º–æ–π –±–ª–∏–∑–∫–æ–π –∫ —Ñ–∞–π–ª—É (—Å–ø—Ä–∞–≤–∞)
            # –ò–¥—ë–º –≤–≤–µ—Ä—Ö –ø–æ –∏–µ—Ä–∞—Ä—Ö–∏–∏ –ø–∞–ø–æ–∫
            parts_to_check = []
            
            # –ó–∞—Ç–µ–º –≤—Å–µ –ø–∞–ø–∫–∏ –≤ –ø—É—Ç–∏ (–æ—Ç –ª–∏—Å—Ç–∞ –∫ –∫–æ—Ä–Ω—é)
            for parent in file_path.parents:
                parts_to_check.append(str(parent))
            
            # –ü–æ–ø—ã—Ç–∞—Ç—å—Å—è –ø–∞—Ä—Å–∏—Ç—å –∫–∞–∂–¥—É—é –ø–∞–ø–∫—É, –∏—Å–ø–æ–ª—å–∑—É—è –∫–µ—à
            parsed_author = None
            for folder_path in parts_to_check:
                # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–µ—à
                if folder_path in folder_cache:
                    parsed_author = folder_cache[folder_path]
                    if parsed_author and parsed_author != "–°–±–æ—Ä–Ω–∏–∫":
                        break  # –ù–∞—à–ª–∏ –≤ –∫–µ—à–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º
                else:
                    # –ü–∞—Ä—Å–∏–º –ø–∞–ø–∫—É –≤ –ø–µ—Ä–≤—ã–π —Ä–∞–∑ –∏ –∫–µ—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    folder_name = Path(folder_path).name
                    parsed_author = self._parse_author_from_folder_name(folder_name)
                    folder_cache[folder_path] = parsed_author  # –ö–µ—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    
                    if parsed_author and parsed_author != "–°–±–æ—Ä–Ω–∏–∫":
                        break  # –ù–∞—à–ª–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç–æ–≥–æ –∞–≤—Ç–æ—Ä–∞
            
            # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –≤ –ø–∞–ø–∫–µ - –ø—Ä–∏–º–µ–Ω–∏—Ç—å
            if parsed_author and parsed_author != "–°–±–æ—Ä–Ω–∏–∫":
                record.proposed_author = parsed_author
                record.author_source = "filename"
                extracted_count += 1
        
        print(f"‚úÖ PASS 2 –∑–∞–≤–µ—Ä—à—ë–Ω: {extracted_count} –∞–≤—Ç–æ—Ä–æ–≤ + {collection_count} —Å–±–æ—Ä–Ω–∏–∫–æ–≤ –∏–∑–≤–ª–µ—á–µ–Ω–æ\n", flush=True)
        print(f"   –ö–µ—à–∏—Ä–æ–≤–∞–Ω–æ –ø–∞–ø–æ–∫: {len(folder_cache)}\n", flush=True)
        self.logger.log(f"[PASS 2] –ò–∑–≤–ª–µ—á–µ–Ω–æ {extracted_count} –∞–≤—Ç–æ—Ä–æ–≤ –∏ {collection_count} —Å–±–æ—Ä–Ω–∏–∫–æ–≤ (–∫–µ—à: {len(folder_cache)} –ø–∞–ø–æ–∫)")
    
    def _pass3_normalize_authors(self) -> None:
        """PASS 3: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ–æ—Ä–º–∞—Ç –∞–≤—Ç–æ—Ä–æ–≤.
        
        "–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤" ‚Üí "–ü–µ—Ç—Ä–æ–≤ –ò–≤–∞–Ω"
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç AuthorName –∫–ª–∞—Å—Å –¥–ª—è –ª–æ–≥–∏–∫–∏.
        """
        print("\n" + "="*80, flush=True)
        print("üî§ PASS 3: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∞ –∞–≤—Ç–æ—Ä–æ–≤...", flush=True)
        print("="*80, flush=True)
        
        self.logger.log("[PASS 3] –ù–∞—á–∞–ª–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ñ–æ—Ä–º–∞—Ç–∞...")
        
        changed_count = 0
        for record in self.records:
            original = record.proposed_author
            apply_author_normalization(record)
            if record.proposed_author != original:
                changed_count += 1
        
        print(f"‚úÖ PASS 3 –∑–∞–≤–µ—Ä—à—ë–Ω: {changed_count} –∞–≤—Ç–æ—Ä–æ–≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ\n", flush=True)
        self.logger.log(f"[PASS 3] –ò–∑–º–µ–Ω–µ–Ω–æ {changed_count} –∞–≤—Ç–æ—Ä–æ–≤")
    
    def _pass4_apply_consensus(self) -> None:
        """PASS 4: –ü—Ä–∏–º–µ–Ω–∏—Ç—å –∫–æ–Ω—Å–µ–Ω—Å—É—Å –∫ –≥—Ä—É–ø–ø–∞–º —Ñ–∞–π–ª–æ–≤.
        
        –§–∞–π–ª—ã —Å author_source="folder_dataset" –ù–ï –º–µ–Ω—è—é—Ç—Å—è.
        –ö–æ–Ω—Å–µ–Ω—Å—É—Å –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫ —Ñ–∞–π–ª–∞–º –≤ –æ–¥–Ω–æ–π –ø–∞–ø–∫–µ —Å source="filename" –∏–ª–∏ "metadata".
        """
        print("\n" + "="*80, flush=True)
        print("ü§ù PASS 4: –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞ –∫ –≥—Ä—É–ø–ø–∞–º...", flush=True)
        print("="*80, flush=True)
        
        self.logger.log("[PASS 4] –ù–∞—á–∞–ª–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞...")
        
        # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≥—Ä—É–ø–ø—ã - parent folder
        def group_by_folder(record: BookRecord) -> str:
            return str(Path(record.file_path).parent)
        
        # –ü—Ä–∏–º–µ–Ω–∏—Ç—å –∫–æ–Ω—Å–µ–Ω—Å—É—Å
        apply_author_consensus(self.records, group_by_folder, self.settings)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        consensus_count = sum(1 for r in self.records if r.author_source == "consensus")
        print(f"‚úÖ PASS 4 –∑–∞–≤–µ—Ä—à—ë–Ω: {consensus_count} —Ñ–∞–π–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–æ–º\n", flush=True)
        self.logger.log("[PASS 4] –ó–∞–≤–µ—Ä—à–µ–Ω–æ")
    
    def _pass5_apply_conversions(self) -> None:
        """PASS 5: –ü–µ—Ä–µ–ø—Ä–∏–º–µ–Ω–∏—Ç—å conversions –ø–æ—Å–ª–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞.
        
        –≠—Ç–æ –Ω—É–∂–Ω–æ –ø–æ—Ç–æ–º—É —á—Ç–æ –∫–æ–Ω—Å–µ–Ω—Å—É—Å –º–æ–∂–µ—Ç –∏–∑–º–µ–Ω–∏—Ç—å –∞–≤—Ç–æ—Ä–∞ –Ω–∞ –¥—Ä—É–≥–æ–≥–æ,
        –∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–ø—Ä–∏–º–µ–Ω–∏—Ç—å conversions –¥–ª—è –Ω–æ–≤–æ–π —Ñ–∞–º–∏–ª–∏–∏.
        """
        print("\n" + "="*80, flush=True)
        print("üîÑ PASS 5: –ü–µ—Ä–µ–ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ conversions –ø–æ—Å–ª–µ –∫–æ–Ω—Å–µ–Ω—Å—É—Å–∞...", flush=True)
        print("="*80, flush=True)
        
        self.logger.log("[PASS 5] –ù–∞—á–∞–ª–æ –ø–µ—Ä–µ–ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è conversions...")
        
        changed_count = 0
        original_authors = {id(r): r.proposed_author for r in self.records}
        
        apply_surname_conversions_to_records(self.records, self.settings)
        
        for record in self.records:
            if record.proposed_author != original_authors.get(id(record)):
                changed_count += 1
        
        print(f"‚úÖ PASS 5 –∑–∞–≤–µ—Ä—à—ë–Ω: {changed_count} –∞–≤—Ç–æ—Ä–æ–≤ –ø–µ—Ä–µ–ø—Ä–∏–º–µ–Ω–µ–Ω—ã conversions\n", flush=True)
        self.logger.log(f"[PASS 5] –ü–µ—Ä–µ–ø—Ä–∏–º–µ–Ω–µ–Ω–æ conversions –∫ {changed_count} –∞–≤—Ç–æ—Ä–∞–º")
    
    def _pass6_expand_abbreviations(self) -> None:
        """PASS 6: –†–∞—Å–∫—Ä—ã—Ç—å –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã –≤ –∏–º–µ–Ω–∞—Ö –∞–≤—Ç–æ—Ä–æ–≤.
        
        "–ò.–ü–µ—Ç—Ä–æ–≤" ‚Üí "–ò–≤–∞–Ω –ü–µ—Ç—Ä–æ–≤"
        –¢—Ä–µ–±—É–µ—Ç –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å–ª–æ–≤–∞—Ä—è –ø–æ–ª–Ω—ã—Ö –∏–º—ë–Ω –∏–∑ –≤—Å–µ—Ö –∞–≤—Ç–æ—Ä–æ–≤.
        """
        print("\n" + "="*80, flush=True)
        print("üìö PASS 6: –†–∞—Å–∫—Ä—ã—Ç–∏–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä –≤ –∏–º–µ–Ω–∞—Ö...", flush=True)
        print("="*80, flush=True)
        
        self.logger.log("[PASS 6] –ù–∞—á–∞–ª–æ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä...")
        
        # –ü–æ—Å—Ç—Ä–æ–∏—Ç—å —Å–ª–æ–≤–∞—Ä—å –∞–≤—Ç–æ—Ä–æ–≤
        authors_map = build_authors_map(self.records, self.settings)
        print(f"  –ü–æ—Å—Ç—Ä–æ–µ–Ω–æ {len(authors_map)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–º–∏–ª–∏–π", flush=True)
        self.logger.log(f"  [PASS 6] –ü–æ—Å—Ç—Ä–æ–µ–Ω–æ {len(authors_map)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–º–∏–ª–∏–π")
        
        # –†–∞—Å–∫—Ä—ã—Ç—å –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã
        expand_abbreviated_authors(self.records, authors_map, self.settings)
        
        print(f"‚úÖ PASS 6 –∑–∞–≤–µ—Ä—à—ë–Ω\n", flush=True)
        self.logger.log("[PASS 6] –ó–∞–≤–µ—Ä—à–µ–Ω–æ")
    
    def _sort_authors_in_records(self) -> None:
        """–û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∞–≤—Ç–æ—Ä–æ–≤ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É –µ—Å–ª–∏ –∏—Ö –Ω–µ—Å–∫–æ–ª—å–∫–æ (—Ä–∞–∑–¥–µ–ª–µ–Ω—ã –∑–∞–ø—è—Ç–æ–π).
        
        –ü—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ –≤—Å–µ–º records –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ—Ç proposed_author –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–æ–≤.
        –†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –∑–∞–ø—è—Ç–∞—è —Å –ø—Ä–æ–±–µ–ª–æ–º ", ".
        """
        for record in self.records:
            if not record.proposed_author or record.proposed_author in ("–°–±–æ—Ä–Ω–∏–∫", "[–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ]"):
                continue
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—Å—Ç—å –ª–∏ –∑–∞–ø—è—Ç–∞—è (–Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä–æ–≤)
            if ',' in record.proposed_author:
                # –†–∞–∑–±–∏—Ç—å –ø–æ –∑–∞–ø—è—Ç–æ–π
                authors = [a.strip() for a in record.proposed_author.split(',')]
                
                # –£–±—Ä–∞—Ç—å –ø—É—Å—Ç—ã–µ
                authors = [a for a in authors if a]
                
                if len(authors) > 1:
                    # –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
                    authors.sort()
                    # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å –æ–±—Ä–∞—Ç–Ω–æ —Å –∑–∞–ø—è—Ç–æ–π
                    record.proposed_author = ", ".join(authors)
    
    def _sort_records(self) -> None:
        """–û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø–∏—Å–∏: —Å–Ω–∞—á–∞–ª–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã, –ø–æ—Ç–æ–º –ø–∞–ø–∫–∏ (–æ–±–µ –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É).
        
        –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—É—Ç–∏:
        - –û—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã: "–°–µ—Ä–∏—è - XXX\File.fb2" (1 backslash)
        - –§–∞–π–ª—ã –≤ –ø–∞–ø–∫–∞—Ö: "–°–µ—Ä–∏—è - XXX\Folder\File.fb2" (2+ backslash)
        """
        # –†–∞–∑–¥–µ–ª–∏—Ç—å –Ω–æ–≤—ã–µ –∏ —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
        single_files = []  # –û—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã (–≥–ª—É–±–∏–Ω–∞ 1)
        folder_files = []  # –§–∞–π–ª—ã –≤ –ø–∞–ø–∫–∞—Ö (–≥–ª—É–±–∏–Ω–∞ 2+)
        
        for record in self.records:
            # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ backslash –≤ –ø—É—Ç–∏
            path_parts = record.file_path.count('\\')
            
            if path_parts == 1:
                single_files.append(record)
            else:
                folder_files.append(record)
        
        # –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ–±–µ –≥—Ä—É–ø–ø—ã –ø–æ file_path (–∞–ª—Ñ–∞–≤–∏—Ç–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫)
        single_files.sort(key=lambda r: r.file_path)
        folder_files.sort(key=lambda r: r.file_path)
        
        # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å: —Å–Ω–∞—á–∞–ª–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ, –ø–æ—Ç–æ–º –ø–∞–ø–∫–∏
        self.records = single_files + folder_files
    
    def _save_csv(self, output_path: str) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ CSV —Ñ–∞–π–ª.
        
        –ö–æ–ª–æ–Ω–∫–∏ CSV (—Å–æ–≥–ª–∞—Å–Ω–æ –ø—É–Ω–∫—Ç—É 6.1 –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏):
        1. file_path - –ø—É—Ç—å –∫ FB2 –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ library_path
        2. metadata_authors - –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∞–≤—Ç–æ—Ä—ã –∏–∑ FB2
        3. proposed_author - —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –∞–≤—Ç–æ—Ä –ø–æ—Å–ª–µ PASS
        4. author_source - –∏—Å—Ç–æ—á–Ω–∏–∫ –∞–≤—Ç–æ—Ä–∞
        5. metadata_series - –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è —Å–µ—Ä–∏—è –∏–∑ FB2
        6. proposed_series - —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Å–µ—Ä–∏—è –ø–æ—Å–ª–µ PASS
        7. series_source - –∏—Å—Ç–æ—á–Ω–∏–∫ —Å–µ—Ä–∏–∏
        8. file_title - –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–Ω–∏–≥–∏
        
        Args:
            output_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        print("\n" + "="*80, flush=True)
        print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ CSV —Ñ–∞–π–ª...", flush=True)
        print("="*80, flush=True)
        
        self.logger.log(f"[CSV] –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ CSV –≤ {output_path}...")
        
        # –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        output_path_obj = Path(output_path)
        output_path_obj.parent.mkdir(parents=True, exist_ok=True)
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ (–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ _sort_records())
        # –ù–µ –ø–µ—Ä–µ–æ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É!
        
        # –ù–∞–ø–∏—Å–∞—Ç—å CSV —Å –≤—Å–µ–º–∏ 8 –∫–æ–ª–æ–Ω–∫–∞–º–∏ —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ 6.1
        fieldnames = [
            'file_path',
            'metadata_authors', 
            'proposed_author', 
            'author_source',
            'metadata_series',
            'proposed_series',
            'series_source',
            'file_title'
        ]
        
        with open(output_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for record in self.records:
                row = {
                    'file_path': record.file_path,
                    'metadata_authors': record.metadata_authors,
                    'proposed_author': record.proposed_author,
                    'author_source': record.author_source,
                    'metadata_series': record.metadata_series,
                    'proposed_series': record.proposed_series,
                    'series_source': record.series_source,
                    'file_title': record.file_title,
                }
                writer.writerow(row)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total = len(self.records)
        by_source = {}
        for record in self.records:
            source = record.author_source
            by_source[source] = by_source.get(source, 0) + 1
        
        # –í—ã–≤–æ–¥ –≤ –∫–æ–Ω—Å–æ–ª—å
        print(f"\n‚úÖ CSV —Å–æ—Ö—Ä–∞–Ω—ë–Ω —É—Å–ø–µ—à–Ω–æ: {total} –∑–∞–ø–∏—Å–µ–π", flush=True)
        print(f"   –ü—É—Ç—å: {output_path}", flush=True)
        print(f"\n   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º:", flush=True)
        for source, count in sorted(by_source.items()):
            print(f"   ‚Ä¢ {source:20s}: {count:4d} ({count*100//total}%)", flush=True)
        print()
        
        self.logger.log(f"‚úÖ [CSV] CSV —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {total} –∑–∞–ø–∏—Å–µ–π")
        for source, count in sorted(by_source.items()):
            self.logger.log(f"  [CSV] {source}: {count}")
    
    def _get_output_csv_path(self) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV —Ñ–∞–π–ª—É.
        
        CSV —Ñ–∞–π–ª –í–°–ï–ì–î–ê —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞ (—Ç–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞) –∫–∞–∫ regen.csv
        –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –µ–¥–∏–Ω—É—é —Ç–æ—á–∫—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç work_dir.
        
        Returns:
            –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É CSV –≤ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞
        """
        # CSV —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ –ø–∞–ø–∫–µ –ø—Ä–æ–µ–∫—Ç–∞ (–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è regen_csv.py)
        project_dir = Path(__file__).parent
        return str(project_dir / 'regen.csv')




def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ CSV."""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='–†–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è CSV —Ñ–∞–π–ª–∞ —Å –∞–≤—Ç–æ—Ä–∞–º–∏ FB2 –±–∏–±–ª–∏–æ—Ç–µ–∫–∏'
    )
    parser.add_argument(
        '--config',
        type=str,
        default='config.json',
        help='–ü—É—Ç—å –∫ config.json (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: config.json)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default=None,
        help='–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: –ø–∞–ø–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞/regen.csv)'
    )
    
    args = parser.parse_args()
    
    service = RegenCSVService(args.config)
    success = service.regenerate(args.output)
    
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
